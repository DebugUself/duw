---
title: "DU12w"
date: 2017-07-01T20:20:00+08:00
---

# æ€¼å‘¨åˆŠ\_v12
\~ é¢„å®š 17.7.1 20:20 å‘å¸ƒ

---- 

æ—¶å·®

	å¤©åœ†åœ°æ–¹è‡ªå¤æ›°
	å…¶å®æ­£å¥½åè¿‡æ¥
	å¤œæ™©å´ä¸ºåœ°è‡ªå½±
	æ—¶åŒºç©¿æ¢­æœ‰å·®å¼‚
	èº«ä½“è€å®è·Ÿä¸ä¸Š
	æ€»ç®—å½’æ¥æŸ¥log
	åˆæ˜¯ä¸ƒå¤©æš—è¿›æ­¥
	è¿æ–°ç­¹å¤‡è¿˜ç¼ºå˜›
	å†å¯æ–°å››å‘¨é¡¹ç›®
	è‡ªæ€¼å°åœˆç¨³å¿ƒæ°”

---- 

- ä¸»ç¼–: [å¤§å¦ˆ][1]
- è´£ç¼–:
	+ [xpgeng][2]
	+ [sunoonlee][3]
	+ [Zoe][4]
	+ [bambooom][5]

# è¿›åº¦
\~ è®°å½•å½“å‘¨å…³é”®äº‹ä»¶æ—¥æœŸ+è¯æ®é“¾æ¥

- 170624 [72h \[ANN] 170624 æ€¼å‘¨ä¼šåŠä¼šè®®çºªè¦][6]
- 170401 å…³é—­æŠ¥è¡¨å’Œå…¥å¯†
- 170331 om103py æ¯•ä¸š

# ä»»åŠ¡
\~ è®°è¿°å…³é”®å…±æ€¼ä»»åŠ¡ (å¦‚æœæ²¡æœ‰, ç•™ç©º)

- 170624 [S04E51 å¯åŠ¨][7]
- 170603 [æ€¼åœˆçš„äºŒæ¬¡å¼€æ”¾ ç­¹å¤‡ä¸­][8]


# è¿›å±•
\~ æ•´ä½“ä¸Šåœˆå†…éƒ¨æ´»è·ƒæŒ‡æ ‡æƒ…å†µ

- æäº¤(S04E051): 7 äºº (6äººå»¶ç»­ä¸ŠæœŸ + 1 ä¸ªæ–°é¡¹ç›®)
   - å°ç»„ @zoomquiet æ—¶é—´å¸å•:æ•ˆèƒ½åˆ†æå°é˜Ÿ
	   - @zoomquiet 
	   - @zsy
	   - @liguanghe
	   - @simpleowen 
	   - @mxclover 
   - @hetao Deep Learning è‡ªå­¦è®¡åˆ’
   - @zoejane è¿›å…¥ Web ä¸–ç•Œ
- å¼•å‘çš„ä½œå“:
	+ @hetao - Deep Learning å­¦ä¹ ç¬”è®°
	+ @zoejane - Demo ç½‘é¡µ
- çŠ¶æ€:

<table>
<tr><th>allcic Commit</th><th> times</th><th>weekly Commit</th><th> times</th></tr>
<tr><td>
            <a href='http://github.com/ZoomQuiet'>ZoomQuiet</a></td><td>255</td>
        <td>
            <a href='http://github.com/zoejane'>zoejane</a></td><td>25</td>
            
<tr><td>
            <a href='http://github.com/zoejane'>zoejane</a></td><td>239</td>
        <td>
            <a href='http://github.com/mxclover'>mxclover</a></td><td>10</td>
            
<tr><td>
            <a href='http://github.com/liguanghe'>liguanghe</a></td><td>117</td>
        <td>
            <a href='http://github.com/zhangshiyinrunwithcc'>zhangshiyinrunwithcc</a></td><td>2</td>
            
<tr><td>
            <a href='http://github.com/mxclover'>mxclover</a></td><td>113</td>
        <td>
            <a href='http://github.com/ZoomQuiet'>ZoomQuiet</a></td><td>1</td>
            
<tr><td>
            <a href='http://github.com/bambooom'>bambooom</a></td><td>107</td>
        <td>
            <a href='http://github.com/livingworld'>livingworld</a></td><td>1</td>
            
<tr><th>all Commit </th><th>Comments times</th><th>weekly Commit</th><th>Comments times</th></tr>
<tr><th>all Issue </th><th>Comments times</th><th>weekly Issue</th><th>Comments times</th></tr>
<tr><td>
            <a href='http://github.com/ZoomQuiet'>ZoomQuiet</a></td><td>307</td>
        <td>
            <a href='http://github.com/zhangshiyinrunwithcc'>zhangshiyinrunwithcc</a></td><td>8</td>
            
<tr><td>
            <a href='http://github.com/zhangshiyinrunwithcc'>zhangshiyinrunwithcc</a></td><td>168</td>
        <td>
            <a href='http://github.com/zoejane'>zoejane</a></td><td>3</td>
            
<tr><td>
            <a href='http://github.com/liguanghe'>liguanghe</a></td><td>129</td>
        <td>
            <a href='http://github.com/mxclover'>mxclover</a></td><td>1</td>
            
<tr><td>
            <a href='http://github.com/zoejane'>zoejane</a></td><td>70</td>
        <td>
            <a href='http://github.com/livingworld'>livingworld</a></td><td>1</td>
            
</table>

\<- 170701 16:22

- åœ¨çº¿(æµ‹è¯•ing..):
	+ `curl du.zoomquiet.us`
	+ `curl du.zoomquiet.us/v0/all/cic/rank/5/`
	+ `curl du.zoomquiet.us/v0/all/cil/rank/5/`
	+ `curl du.zoomquiet.us/v0/week/cic/rank/5/`
	+ `curl du.zoomquiet.us/v0/week/cil/rank/5/`


# æˆæœ
\~ å„ç§æˆå“/åŠæˆå“ å†…éƒ¨çŸ¥è¯†ä½œå“

## @hetao - Deep Learningå­¦ä¹ ç¬”è®°

- [DebugUself/du4proto at hetao][9]
- @hetao ç«¥é‹è¿‘æœŸåœ¨ GitHub æ›´æ–°äº†è‡ªå·±è¿™å‡ å‘¨ä»¥æ¥å¯¹äº Depp Learning éå¸¸è¯¦ç»†çš„å­¦ä¹ ç¬”è®°,æ¨è!

### 20170626 Skip-gram word2 ç¬”è®°

Skip-Gramä¸»è¦æ˜¯ç»™å®šinput wordæ¥é¢„æµ‹ä¸Šä¸‹æ–‡,åŒºåˆ«äºCBOWç»™å®šä¸Šä¸‹æ–‡é¢„æµ‹input word. 

Word2Vecæ¨¡å‹å®é™…ä¸Šåˆ†ä¸ºäº†ä¸¤ä¸ªéƒ¨åˆ†,ç¬¬ä¸€éƒ¨åˆ†ä¸ºå»ºç«‹æ¨¡å‹,ç¬¬äºŒéƒ¨åˆ†æ˜¯é€šè¿‡æ¨¡å‹è·å–åµŒå…¥è¯å‘é‡. 

### ç¬¬ä¸€éƒ¨åˆ†:æ¨¡å‹
#### Fake Task

- å°è±¡:è®­ç»ƒæ¨¡å‹çš„çœŸæ­£ç›®çš„æ˜¯è·å¾—æ¨¡å‹åŸºäºè®­ç»ƒæ•°æ®å­¦å¾—çš„éšå±‚æƒé‡. ä¸ºäº†å¾—åˆ°è¿™äº›æƒé‡,æˆ‘ä»¬é¦–å…ˆéœ€è¦æ„å»ºå®Œæ•´çš„ç¥ç»ç½‘ç»œä½œä¸ºæˆ‘ä»¬çš„"Fake Task". 
- ä¾‹å­:ä»¥ä¸€ä¸ªå¥å­`"The dog barked at the mailman"`çš„è¾“å…¥ä¸ºä¾‹. 
	+ é¦–é€‰é€‰æ‹©,å•è¯"dog"ä½œä¸ºinput word. 
	+ å…¶æ¬¡,å®šä¹‰ä¸€ä¸ªå«åš**skip\_window**çš„å‚æ•°,å®ƒä»£è¡¨ç€æˆ‘ä»¬ä»å½“å‰input wordçš„ä¸€ä¾§(å·¦è¾¹æˆ–å³è¾¹)é€‰å–è¯çš„æ•°é‡. å¦‚æœæˆ‘ä»¬è®¾ç½®`skip_window=2`,é‚£ä¹ˆæˆ‘ä»¬æœ€ç»ˆè·å¾—çª—å£ä¸­çš„è¯(åŒ…æ‹¬input wordåœ¨å†…)å°±æ˜¯['The', 'dog','barked', 'at']. `skip_window=2`ä»£è¡¨ç€é€‰å–å·¦input wordå·¦ä¾§2ä¸ªè¯å’Œå³ä¾§2ä¸ªè¯è¿›å…¥æˆ‘ä»¬çš„çª—å£,æ‰€ä»¥æ•´ä¸ªçª—å£å¤§å°span=2x2=4. 
	+ å¦ä¸€ä¸ªå‚æ•°å«**num\_skips**,å®ƒä»£è¡¨ç€æˆ‘ä»¬ä»æ•´ä¸ªçª—å£ä¸­é€‰å–å¤šå°‘ä¸ªä¸åŒçš„è¯ä½œä¸ºæˆ‘ä»¬çš„output word,å½“`skip_window=2`,`num_skips=2`æ—¶,æˆ‘ä»¬å°†ä¼šå¾—åˆ°ä¸¤ç»„ (input word, output word) å½¢å¼çš„è®­ç»ƒæ•°æ®,å³ ('dog', 'barked'),('dog', 'the'). 
	+ ç¥ç»ç½‘ç»œåŸºäºè¿™äº›è®­ç»ƒæ•°æ®å°†ä¼šè¾“å‡ºä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒ,è¿™ä¸ªæ¦‚ç‡ä»£è¡¨ç€æˆ‘ä»¬çš„è¯å…¸ä¸­çš„æ¯ä¸ªè¯æ˜¯output wordçš„å¯èƒ½æ€§. ä¾‹å¦‚æˆ‘ä»¬å…ˆæ‹¿ä¸€ç»„æ•°æ® ('dog', 'barked') æ¥è®­ç»ƒç¥ç»ç½‘ç»œ,é‚£ä¹ˆæ¨¡å‹é€šè¿‡å­¦ä¹ è¿™ä¸ªè®­ç»ƒæ ·æœ¬,ä¼šå‘Šè¯‰æˆ‘ä»¬è¯æ±‡è¡¨ä¸­æ¯ä¸ªå•è¯æ˜¯"barked"çš„æ¦‚ç‡å¤§å°. 
	+ æ¨¡å‹çš„è¾“å‡ºæ¦‚ç‡ä»£è¡¨ç€åˆ°æˆ‘ä»¬è¯å…¸ä¸­æ¯ä¸ªè¯æœ‰å¤šå¤§å¯èƒ½æ€§è·Ÿinput wordåŒæ—¶å‡ºç°. 
	+ **window\_size=2**è¡¨ç¤ºé€‰æ‹©è¾“å…¥è¯å‰åå„ä¸¤ä¸ªè¯å’Œè¾“å…¥è¯è¿›è¡Œç»„åˆ,å¦‚å›¾è“è‰²ä»£è¡¨input word,æ–¹æ¡†å†…ä»£è¡¨ä½äºçª—å£å†…çš„å•è¯,ç”±å›¾å¯çŸ¥,å¯ä»¥ç»Ÿè®¡è¯æ±‡ç»„åˆå‡ºç°æ¦‚ç‡é«˜ä½. 
		* ![][image-1]
#### æ¨¡å‹ç»†èŠ‚

- é¦–é€‰æ„å»ºè‡ªå·±çš„è¯æ±‡è¡¨(vocabulary)å†å¯¹å•è¯è¿›è¡Œone-hotç¼–ç . 
- å‡è®¾ä»æˆ‘ä»¬çš„è®­ç»ƒæ–‡æ¡£ä¸­æŠ½å–å‡º10000ä¸ªå”¯ä¸€ä¸é‡å¤çš„å•è¯ç»„æˆè¯æ±‡è¡¨. æˆ‘ä»¬å¯¹è¿™10000ä¸ªå•è¯è¿›è¡Œone-hotç¼–ç ,å¾—åˆ°çš„æ¯ä¸ªå•è¯éƒ½æ˜¯ä¸€ä¸ª10000ç»´çš„å‘é‡,å‘é‡æ¯ä¸ªç»´åº¦çš„å€¼åªæœ‰0æˆ–è€…1,å‡å¦‚å•è¯antsåœ¨è¯æ±‡è¡¨ä¸­çš„å‡ºç°ä½ç½®ä¸ºç¬¬3ä¸ª,é‚£ä¹ˆantsçš„å‘é‡å°±æ˜¯ä¸€ä¸ªç¬¬ä¸‰ç»´åº¦å–å€¼ä¸º1,å…¶ä»–ç»´éƒ½ä¸º0çš„10000ç»´çš„å‘é‡($ants=[0, 0, 1, 0, ..., 0]$). 
- è¿˜æ˜¯ä¸Šé¢çš„ä¾‹å­,"The dog barked at the mailman",é‚£ä¹ˆæˆ‘ä»¬åŸºäºè¿™ä¸ªå¥å­,å¯ä»¥æ„å»ºä¸€ä¸ªå¤§å°ä¸º5çš„è¯æ±‡è¡¨(å¿½ç•¥å¤§å°å†™å’Œæ ‡ç‚¹ç¬¦å·):("the", "dog", "barked", "at", "mailman"),æˆ‘ä»¬å¯¹è¿™ä¸ªè¯æ±‡è¡¨çš„å•è¯è¿›è¡Œç¼–å·0-4. é‚£ä¹ˆ"dog"å°±å¯ä»¥è¢«è¡¨ç¤ºä¸ºä¸€ä¸ª5ç»´å‘é‡[0, 1, 0, 0, 0]. 
- æ¨¡å‹çš„è¾“å…¥å¦‚æœä¸ºä¸€ä¸ª10000ç»´çš„å‘é‡,é‚£ä¹ˆè¾“å‡ºä¹Ÿæ˜¯ä¸€ä¸ª10000ç»´åº¦(è¯æ±‡è¡¨çš„å¤§å°)çš„å‘é‡,å®ƒåŒ…å«äº†10000ä¸ªæ¦‚ç‡,æ¯ä¸€ä¸ªæ¦‚ç‡ä»£è¡¨ç€å½“å‰è¯æ˜¯è¾“å…¥æ ·æœ¬ä¸­output wordçš„æ¦‚ç‡å¤§å°. 
- ![][image-2]
- éšå±‚æ²¡æœ‰ä½¿ç”¨ä»»ä½•æ¿€æ´»å‡½æ•°,ä½†æ˜¯è¾“å‡ºå±‚ä½¿ç”¨äº†sotfmax. 
- æˆ‘ä»¬åŸºäºæˆå¯¹çš„å•è¯æ¥å¯¹ç¥ç»ç½‘ç»œè¿›è¡Œè®­ç»ƒ,è®­ç»ƒæ ·æœ¬æ˜¯ ( input word, output word ) è¿™æ ·çš„å•è¯å¯¹,input wordå’Œoutput wordéƒ½æ˜¯one-hotç¼–ç çš„å‘é‡. æœ€ç»ˆæ¨¡å‹çš„è¾“å‡ºæ˜¯ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒ. 

#### éšå±‚

ç”¨300ä¸ªç‰¹å¾èŠ‚ç‚¹è¡¨ç¤ºä¸€ä¸ªå•è¯,å³ç”¨300ç»´å‘é‡è¡¨ç¤º,åˆ™éšè—å±‚æƒé‡çŸ©é˜µä¸º10000x300ç»´åº¦. 
çœ‹ä¸‹é¢çš„å›¾ç‰‡,å·¦å³ä¸¤å¼ å›¾åˆ†åˆ«ä»ä¸åŒè§’åº¦ä»£è¡¨äº†è¾“å…¥å±‚-éšå±‚çš„æƒé‡çŸ©é˜µ. å·¦å›¾ä¸­æ¯ä¸€åˆ—ä»£è¡¨ä¸€ä¸ª10000ç»´çš„è¯å‘é‡å’Œéšå±‚å•ä¸ªç¥ç»å…ƒè¿æ¥çš„æƒé‡å‘é‡. ä»å³è¾¹çš„å›¾æ¥çœ‹,æ¯ä¸€è¡Œå®é™…ä¸Šä»£è¡¨äº†æ¯ä¸ªå•è¯çš„è¯å‘é‡. 

ä¸Šé¢æˆ‘ä»¬æåˆ°,input wordå’Œoutput wordéƒ½ä¼šè¢«æˆ‘ä»¬è¿›è¡Œone-hotç¼–ç . å¦‚æœæˆ‘ä»¬å°†ä¸€ä¸ª1 x 10000çš„å‘é‡å’Œ10000 x 300çš„çŸ©é˜µç›¸ä¹˜,å®ƒä¼šæ¶ˆè€—ç›¸å½“å¤§çš„è®¡ç®—èµ„æº,ä¸ºäº†é«˜æ•ˆè®¡ç®—,å®ƒä»…ä»…ä¼šé€‰æ‹©çŸ©é˜µä¸­å¯¹åº”çš„å‘é‡ä¸­ç»´åº¦å€¼ä¸º1çš„ç´¢å¼•è¡Œ(è¿™å¥è¯å¾ˆç»•),çœ‹å›¾å°±æ˜ç™½. 

ä¸Šé¢çš„ä¾‹å­ä¸­,å·¦è¾¹å‘é‡ä¸­å–å€¼ä¸º1çš„å¯¹åº”ç»´åº¦ä¸º3(ä¸‹æ ‡ä»0å¼€å§‹),é‚£ä¹ˆè®¡ç®—ç»“æœå°±æ˜¯çŸ©é˜µçš„ç¬¬3è¡Œ(ä¸‹æ ‡ä»0å¼€å§‹)--- [10, 12, 19],è¿™æ ·æ¨¡å‹ä¸­çš„éšå±‚æƒé‡çŸ©é˜µä¾¿æˆäº†ä¸€ä¸ª"æŸ¥æ‰¾è¡¨"(lookup table),

#### è¾“å‡ºå±‚

ç»è¿‡ç¥ç»ç½‘ç»œéšå±‚çš„è®¡ç®—,antsè¿™ä¸ªè¯ä¼šä»ä¸€ä¸ª1 x 10000çš„å‘é‡å˜æˆ1 x 300çš„å‘é‡,å†è¢«è¾“å…¥åˆ°è¾“å‡ºå±‚. è¾“å‡ºå±‚æ˜¯ä¸€ä¸ªsoftmaxå›å½’åˆ†ç±»å™¨,å®ƒçš„æ¯ä¸ªç»“ç‚¹å°†ä¼šè¾“å‡ºä¸€ä¸ª0-1ä¹‹é—´çš„å€¼(æ¦‚ç‡),è¿™äº›æ‰€æœ‰è¾“å‡ºå±‚ç¥ç»å…ƒç»“ç‚¹çš„æ¦‚ç‡ä¹‹å’Œä¸º1. 
ä¸‹é¢æ˜¯ä¸€ä¸ªä¾‹å­,è®­ç»ƒæ ·æœ¬ä¸º (input word: "ants", output word: "car") çš„è®¡ç®—ç¤ºæ„å›¾. 
![][image-3]

#### ç›´è§‰ä¸Šçš„ç†è§£

é’ˆå¯¹ä¸Šä¸‹æ–‡ç›¸ä¼¼çš„æƒ…å†µ,è¿›è¡Œè¯å¹²è¯(stemming),å°±æ˜¯å»é™¤è¯ç¼€å¾—åˆ°è¯æ ¹çš„è¿‡ç¨‹. 

### ç¬¬äºŒéƒ¨åˆ† åŸºäºskip-gramæ¨¡å‹çš„é«˜æ•ˆè®­ç»ƒ

é’ˆå¯¹æƒé‡çŸ©é˜µè¿‡å¤§çš„é—®é¢˜,Word2Vecåšå‡ºäº†å¦‚ä¸‹ä¼˜åŒ–:

- å°†å¸¸è§çš„å•è¯ç»„åˆ(word pairs)æˆ–è€…è¯ç»„ä½œä¸ºå•ä¸ª"words"æ¥å¤„ç†. 
- å¯¹é«˜é¢‘æ¬¡å•è¯è¿›è¡ŒæŠ½æ ·æ¥å‡å°‘è®­ç»ƒæ ·æœ¬çš„ä¸ªæ•°. 
- å¯¹ä¼˜åŒ–ç›®æ ‡é‡‡ç”¨"negative sampling"æ–¹æ³•,è¿™æ ·æ¯ä¸ªè®­ç»ƒæ ·æœ¬çš„è®­ç»ƒåªä¼šæ›´æ–°ä¸€å°éƒ¨åˆ†çš„æ¨¡å‹æƒé‡,ä»è€Œé™ä½è®¡ç®—è´Ÿæ‹…. 

è¿™æ˜¯ä¸€ä¸ª[æ¨¡å‹è¯æ±‡è¡¨][10],åŠ[vocabulary][11],ç›¸åº”çš„è®ºæ–‡æœ‰[Distributed Representations of Words and Phrases
and their Compositionality](https://arxiv.org/pdf/1310.4546.pdf),[ä»£ç ][12]. 

#### å¯¹é«˜é¢‘è¯æŠ½æ ·

å¦‚ä¸‹å›¾æ‰€ç¤º,å¯¹äº"the"è¿™ç§å¸¸ç”¨é«˜é¢‘å•è¯,æ—¢æ— æ„ä¹‰,åˆçš„æ¯”é‡å¤§. å¯¹äºæˆ‘ä»¬åœ¨è®­ç»ƒåŸå§‹æ–‡æœ¬ä¸­é‡åˆ°çš„æ¯ä¸€ä¸ªå•è¯,å®ƒä»¬éƒ½æœ‰ä¸€å®šæ¦‚ç‡è¢«æˆ‘ä»¬ä»æ–‡æœ¬ä¸­åˆ æ‰,è€Œè¿™ä¸ªè¢«åˆ é™¤çš„æ¦‚ç‡ä¸å•è¯çš„é¢‘ç‡æœ‰å…³. 
![][image-4]

#### æŠ½æ ·ç‡
åœ¨è¯­æ–™åº“ä¸­,è¯¥è¯å‡ºç°æ¦‚ç‡è¶Šä½,è¶Šæœ‰å¯èƒ½è¢«ä¿ç•™. $P(w\_i)=1-\sqrt{\frac{t}{f(w\_i)}}$. åœ¨ä»£ç ä¸­è¿˜æœ‰ä¸€ä¸ªå‚æ•°å«"sample",è¿™ä¸ªå‚æ•°ä»£è¡¨ä¸€ä¸ªé˜ˆå€¼,é»˜è®¤å€¼ä¸º0.001,è¿™ä¸ªå€¼è¶Šä½,è¶Šä¸å®¹æ˜“ä¿ç•™,å³$P(w\_i)$è¶Šå¤§. 

#### è´Ÿé‡‡æ ·(negative sampling)

- å°è±¡:ç”¨æ¥æé«˜è®­ç»ƒé€Ÿåº¦å¹¶ä¸”æ”¹å–„æ‰€å¾—åˆ°è¯å‘é‡çš„è´¨é‡çš„ä¸€ç§æ–¹æ³•. ä¸åŒäºåŸæœ¬æ¯ä¸ªè®­ç»ƒæ ·æœ¬æ›´æ–°æ‰€æœ‰çš„æƒé‡,è´Ÿé‡‡æ ·æ¯æ¬¡è®©ä¸€ä¸ªè®­ç»ƒæ ·æœ¬ä»…ä»…æ›´æ–°ä¸€å°éƒ¨åˆ†çš„æƒé‡,è¿™æ ·å°±ä¼šé™ä½æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­çš„è®¡ç®—é‡. 
- ä¾‹å­:
	+ å½“æˆ‘ä»¬ç”¨è®­ç»ƒæ ·æœ¬ ( input word: "fox",output word: "quick") æ¥è®­ç»ƒæˆ‘ä»¬çš„ç¥ç»ç½‘ç»œæ—¶,"fox"å’Œ"quick"éƒ½æ˜¯ç»è¿‡one-hotç¼–ç çš„. å¦‚æœæˆ‘ä»¬çš„vocabularyå¤§å°ä¸º10000æ—¶,åœ¨è¾“å‡ºå±‚,æˆ‘ä»¬æœŸæœ›å¯¹åº”"quick"å•è¯çš„é‚£ä¸ªç¥ç»å…ƒç»“ç‚¹è¾“å‡º1,å…¶ä½™9999ä¸ªéƒ½åº”è¯¥è¾“å‡º0. åœ¨è¿™é‡Œ,è¿™9999ä¸ªæˆ‘ä»¬æœŸæœ›è¾“å‡ºä¸º0çš„ç¥ç»å…ƒç»“ç‚¹æ‰€å¯¹åº”çš„å•è¯æˆ‘ä»¬ç§°ä¸º"negative" word. 
	+ å¦‚æœä½¿ç”¨äº†è´Ÿé‡‡æ ·çš„æ–¹æ³•æˆ‘ä»¬ä»…ä»…å»æ›´æ–°æˆ‘ä»¬çš„positive word-"quick"çš„å’Œæˆ‘ä»¬é€‰æ‹©çš„å…¶ä»–5ä¸ªnegative wordsçš„ç»“ç‚¹å¯¹åº”çš„æƒé‡,å…±è®¡6ä¸ªè¾“å‡ºç¥ç»å…ƒ,ç›¸å½“äºæ¯æ¬¡åªæ›´æ–°$300x 6=1800$ä¸ªæƒé‡. 
	+ åœ¨è®ºæ–‡ä¸­,ä½œè€…æŒ‡å‡ºæŒ‡å‡ºå¯¹äºå°è§„æ¨¡æ•°æ®é›†,é€‰æ‹©5-20ä¸ªnegative wordsä¼šæ¯”è¾ƒå¥½,å¯¹äºå¤§è§„æ¨¡æ•°æ®é›†å¯ä»¥ä»…é€‰æ‹©2-5ä¸ªnegative words. 

#### å¦‚ä½•é€‰æ‹©negative words

æˆ‘ä»¬ä½¿ç”¨"ä¸€å…ƒæ¨¡å‹åˆ†å¸ƒ(unigram distribution)"æ¥é€‰æ‹©"negative words". è¦æ³¨æ„çš„ä¸€ç‚¹æ˜¯,ä¸€ä¸ªå•è¯è¢«é€‰ä½œnegative sampleçš„æ¦‚ç‡è·Ÿå®ƒå‡ºç°çš„é¢‘æ¬¡æœ‰å…³,å‡ºç°é¢‘æ¬¡è¶Šé«˜çš„å•è¯è¶Šå®¹æ˜“è¢«é€‰ä½œnegative words. 
ä»£ç å…¬å¼å¦‚ä¸‹:
$P(w\_i)=\frac{f(w\_i)^{3/4}}{\sum\_{j=0}^n(f(w\_j)^{3/4})}$
æ¯ä¸ªå•è¯è¢«èµ‹äºˆä¸€ä¸ªæƒé‡,å³$f(w\_i)$, å®ƒä»£è¡¨ç€å•è¯å‡ºç°çš„é¢‘æ¬¡. å…¬å¼ä¸­å¼€3/4çš„æ ¹å·å®Œå…¨æ˜¯åŸºäºç»éªŒçš„,è®ºæ–‡ä¸­æåˆ°è¿™ä¸ªå…¬å¼çš„æ•ˆæœè¦æ¯”å…¶å®ƒå…¬å¼æ›´åŠ å‡ºè‰². 

- [cè¯­è¨€å®ç°ä»£ç ][13]
- [Word2Vec Resourcesæ•™ç¨‹][14]

### ç¬¬ä¸‰éƒ¨åˆ†:åŸºäºTensorFlowå®ç°Skip-Gramæ¨¡å‹

åˆ†ä¸ºå››éƒ¨åˆ†:

- æ•°æ®é¢„å¤„ç†
- è®­ç»ƒæ ·æœ¬æ„å»º
	+ é‡‡æ ·
	+ æ„é€ batch
		* æ‰¾åˆ°æ¯ä¸ªinput wordçš„ä¸Šä¸‹æ–‡:å¦‚æœæˆ‘ä»¬å›ºå®šskip\_window=2çš„è¯,é‚£ä¹ˆfoxçš„ä¸Šä¸‹æ–‡å°±æ˜¯[quick, brown, jumps, over]. 
			- æˆ‘åœ¨å®é™…é€‰æ‹©input wordä¸Šä¸‹æ–‡æ—¶,ä½¿ç”¨çš„çª—å£å¤§å°æ˜¯ä¸€ä¸ªä»‹äº[1, window\_size]åŒºé—´çš„éšæœºæ•°. è¿™é‡Œçš„ç›®çš„æ˜¯è®©æ¨¡å‹æ›´å¤šåœ°å»å…³æ³¨ç¦»input wordæ›´è¿‘è¯.
		* åŸºäºä¸Šä¸‹æ–‡æ„å»ºbatch:å¦‚æœæˆ‘ä»¬çš„batch\_size=1çš„è¯,é‚£ä¹ˆå®é™…ä¸Šä¸€ä¸ªbatchä¸­æœ‰å››ä¸ªè®­ç»ƒæ ·æœ¬. 

- æ¨¡å‹æ„å»º
	+ è¾“å…¥å±‚åˆ°åµŒå…¥å±‚
		* è¾“å…¥å±‚åˆ°éšå±‚çš„æƒé‡çŸ©é˜µä½œä¸ºåµŒå…¥å±‚è¦ç»™å®šå…¶ç»´åº¦,ä¸€èˆ¬embeding\_sizeè®¾ç½®ä¸º50-300ä¹‹é—´.
	+ åµŒå…¥å±‚åˆ°è¾“å‡ºå±‚
		* TensorFlowä¸­çš„sampled\_softmax\_loss,ç”±äºè¿›è¡Œäº†negative sampling,æ‰€ä»¥å®é™…ä¸Šæˆ‘ä»¬ä¼šä½ä¼°æ¨¡å‹çš„è®­ç»ƒloss. 
			- æœ‰ç‚¹å„¿è´¹è§£.
- æ¨¡å‹éªŒè¯


#### å‚è€ƒèµ„æº

- [A really good conceptual overview of word2vec from Chris McCormick][15]
- [First word2vec paper from Mikolov et al.][16]
- [NIPS paper with improvements for word2vec also from Mikolov et al.][17]
- [An implementation of word2vec from Thushan Ganegedara][18]
- [TensorFlow word2vec tutorial][19]
- [çŸ¥ä¹ä¸“æ ][20]

### é›¶ç¢å¡ç‰‡
#### Word embeddings

- å°è±¡:one-hot encodeæ•ˆç‡å¤ªä½,æµªè´¹è®¡ç®—èµ„æº. ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜,é‡‡ç”¨äº†æ‰€è°“embeddings,é€šè¿‡ç›´æ¥ä»æƒé‡çŸ©é˜µä¸­è·å–éšè—å±‚å€¼æ¥è·³è¿‡åµŒå…¥å±‚çš„ä¹˜æ³•,å³ä½¿ç”¨æƒé‡çŸ©é˜µä½œä¸ºæŸ¥æ‰¾è¡¨. 
- ä¾‹å­:ä¾‹å¦‚"heart"è¢«ç¼–ç ä¸º958,"mind"ä¸º18094.ç„¶åä¸ºäº†è·å–"heart"çš„éšè—å±‚å€¼,åªéœ€è¦åµŒå…¥çŸ©é˜µçš„ç¬¬958è¡Œ. è¿™ä¸ªè¿‡ç¨‹ç§°ä¸ºåµŒå…¥å¼æŸ¥æ‰¾,éšè—å•å…ƒçš„æ•°é‡æ˜¯åµŒå…¥ç»´åº¦. 
	+ ![][image-5]
	+ ![][image-6]

#### Word2Vec

- å°è±¡:ä¸¤ç§å®ç°Word2Vecçš„ç»“æ„:
	+ CBOW (Continuous Bag-Of-Words)
	+ Skip-gram
	![][image-7]

#### Preprocessing

å°è±¡:æ ¹æ®è¯é¢‘æ’åº,é¢‘ç‡æœ€é«˜çš„ä¸º0,å…¶æ¬¡ä¸º1,ä¾æ¬¡æ’åº. æœ€ç»ˆ,è¾“å…¥ä¸€æ®µwords,è¾“å‡ºçš„æ˜¯ä¸€æ®µæ–‡å­—ä¸­å•è¯å¯¹åº”çš„åºåˆ—ä½ç½®. 

#### Subsampling

- å°è±¡:å»é™¤ä¸€äº›æ— æ„ä¹‰çš„è¯æ±‡. å…¬å¼è¡¨è¾¾å¼ä¸º:
$P(w\_i)=1-\sqrt{\frac{t}{f(w\_i)}}$
å…¶ä¸­,tæ˜¯æƒ©ç½šå‚æ•°,$f(w\_i)$æ˜¯$w\_i$åœ¨æ•°æ®é›†ä¸­çš„é¢‘ç‡,$P(w\_i)$æ˜¯ä¸¢å¼ƒwordçš„æ¦‚ç‡
- ä¾‹å­:å°†ä¸€äº›æ— æ„ä¹‰çš„è¯æ±‡,ä¾‹å¦‚"the","of"ç­‰å»é™¤.

#### Making batches

- å°è±¡:è·å–ä¸€æ®µè¯å‰åçš„wordä¸ªæ•°. 
- ä¾‹å­:

```
def get_target(words, idx, window_size=5):
    ''' Get a list of words in a window around an index. '''
    R = np.random.randint(1, window_size+1)
    start = idx - R if (idx - R) > 0 else 0
    stop = idx + R
    target_words = set(words[start:idx] + words[idx+1:stop+1]) # åˆ‡ç‰‡ä¹‹åæ‰“ä¹±äº†é¡ºåº

    # Your code here
    return list(target_words)
```

## zoejane - Demo ç½‘é¡µ

* [Project Plan][21]
* [Demo ç½‘é¡µ][22]

## æ—¶é—´å¸å•:æ•ˆèƒ½åˆ†æå°é˜Ÿ æ¨è¿›ä¸­

- ç»„å‘˜
	* `(ï¿£â–½ï¿£)` -\> å¤§å¦ˆ
	* ğŸ» `ç†Š` =\> @zhangshiyinrunwithcc
	* ğŸ£ `é¹¤` =\> @æå¹¿é¹¤
	* ğŸˆ `çŒ«` =\> @simpleowen
	* ğŸ´ `mx` =\> @mxclover
-  ç›®æ ‡
	- é€šè¿‡åˆ†æå¤§å¦ˆå’Œå‰‘é£, ä¸¤äºº5å¹´ä»¥ä¸ŠæŒç»­æ—¶é—´å¸å•çš„æ•°æ®
	- è·å¾—æ•°æ®åŒ–çš„è¡Œä¸ºæ•ˆèƒ½ç»“è®º
	- å¯¹è‡ªèº«è¡Œä¸ºç»™å‡ºå‡ ç‚¹ä¼˜åŒ–ç­–ç•¥
- [Github é¡¹ç›®é“¾æ¥][23]
- [Project Plan][24]  

# æ•…äº‹
\~ æ”¶é›†å„è‡ªæ— æ³•é›·åŒçš„æ€¼åœˆçœŸäººæ•…äº‹...

# æ¨è
\~ å—¯å“¼å„ç§æ€¼è·¯ä¸Šå‘ç°çš„å—¯å“¼...


# åè®°
\~ æ€¼å‘¨åˆŠæ˜¯ä»€ä¹ˆä»¥åŠä¸ºä»€ä¹ˆå’Œèƒ½æ€ä¹ˆ...

å¤§å¦ˆæ›°è¿‡: `å‚å·®å¤šæ€ æ‰æ˜¯ç”Ÿæœº`
é—®é¢˜åœ¨ `å‚å·®` çš„è¡Œä¸ºæ˜¯æ— æ³•å½¢æˆå›¢é˜Ÿçš„

	Coming together is a beginning; 
	Keeping together is progress; 
	Working together is success!

\<--- [Henry Ford][25]

- æ‰€ä»¥, æœ‰äº† å¤§å¦ˆ éšè§éšæ€¼çš„æŒç»­å—¯å“¼...
- ä½†æ˜¯, æƒ³è±¡ä¸€å¹´å, å›æƒ³å‡ åå‘¨å‰è‡ªå·±ä½œçš„é‚£äº› `å›¾æ ·å›¾æ£®ç ´` 
- å´æ²¡ç°æˆçš„èµ„æ–™æ¥å‡ºç¤ºç»™åè¿›æ¥å—¯å“¼?
- ä¸ç§‘å­¦, å€¼å¾—è®°å½•çš„, å°±åº”å½“æœ‰ä¸ªå½¢å¼å›ºå®šä¸‹æ¥
- æ‰€ä»¥,æœ‰äº†è¿™ä¸ª `æ€¼å‘¨åˆŠ` (Weekly 4 DU)


[1]:	http://du.zoomquiet.io/2014-02/ac0-zq/
[2]:	http://du.zoomquiet.io/2017-04/about-xpgeng/
[3]:	http://du.zoomquiet.io/2017-04/about-sunoonlee/
[4]:	http://du.zoomquiet.io/2017-04/about-zoe/
[5]:	http://du.zoomquiet.io/2017-04/about-bambooom/
[6]:	https://github.com/DebugUself/du4proto/issues/148
[7]:	https://github.com/DebugUself/du4proto/blob/master/S04E51/README.md
[8]:	https://github.com/DebugUself/du4proto/issues/135
[9]:	https://github.com/DebugUself/du4proto/tree/hetao
[10]:	http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/
[11]:	https://github.com/chrisjmccormick/inspect_word2vec/tree/master/vocabulary
[12]:	https://code.google.com/archive/p/word2vec/
[13]:	https://github.com/chrisjmccormick/word2vec_commented
[14]:	https://github.com/chrisjmccormick/word2vec_commented
[15]:	http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/
[16]:	https://arxiv.org/pdf/1301.3781.pdf
[17]:	http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
[18]:	http://www.thushv.com/natural_language_processing/word2vec-part-1-nlp-with-deep-learning-with-tensorflow-skip-gram/
[19]:	https://www.tensorflow.org/tutorials/word2vec
[20]:	https://zhuanlan.zhihu.com/zhaoyeyu
[21]:	https://github.com/DebugUself/du4proto/blob/master/S04E51/du_s04e51_zoejane_plan.md
[22]:	http://blog.zoejane.net/learn-web
[23]:	https://github.com/DebugUself/du4proto/tree/atl4dama
[24]:	https://github.com/DebugUself/du4proto/blob/master/S03E51/du_s03e51_zoomquiet_plan.md
[25]:	https://www.brainyquote.com/quotes/quotes/h/henryford121997.html

[image-1]:	https://raw.githubusercontent.com/DebugUself/du4proto/hetao/week8/note/images/window_size.png?token=ABQhvBWcLwFRicNJ1heHDKnP-yo3GPRRks5ZYEqlwA==
[image-2]:	https://raw.githubusercontent.com/DebugUself/du4proto/hetao/week8/note/images/neural_network.png?token=ABQhvNCC06XQfJwEMwBAZufGtntBrecgks5ZYEq5wA==
[image-3]:	https://raw.githubusercontent.com/DebugUself/du4proto/hetao/week8/note/images/input_output.png?token=ABQhvPeeIv6dMuE67Lo4hj5LYmjB2MnWks5ZYErMwA==
[image-4]:	https://raw.githubusercontent.com/DebugUself/du4proto/hetao/week8/note/images/window_size.png?token=ABQhvLEjfwZz2EuoVM_DN8ZqQCWUNtrZks5ZYErdwA==
[image-5]:	https://raw.githubusercontent.com/DebugUself/du4proto/hetao/week8/note/images/lookup_matrix.png?token=ABQhvOms5WWP6LWu8qx0iukDk9CYQ4Ouks5ZYEtMwA==
[image-6]:	https://raw.githubusercontent.com/DebugUself/du4proto/hetao/week8/note/images/tokenize_lookup.png?token=ABQhvLHc3PWG3nLblV-ZTa1gk5jGDxpPks5ZYEtzwA==
[image-7]:	https://raw.githubusercontent.com/DebugUself/du4proto/hetao/week8/note/images/word2vec_architectures.png?token=ABQhvNFrrnOwVj9uK9LSkao02U8ZSecoks5ZYEuKwA==